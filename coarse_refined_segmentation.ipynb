{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Saliency Segmentation using 3D Gray-Code Kernels\n",
    "#### Elena Nicora, MaLGa Centre, UniGe (2022) \n",
    "-----------------------------------------------------------------------------------------\n",
    "This code implements the entire **Attentive Module** of \n",
    "\n",
    "> \"On the use of efficient projection kernels for motion-based visual saliency estimation.\"\n",
    "Nicora, Elena, and Nicoletta Noceti. Frontiers in Computer Science: 67.\n",
    "\n",
    "The algorithm requires in input a pair of maps, max_pooling and avg_pooling, and returns a refined segmentation of the moving object in the scene.\n",
    "\n",
    "**IMPORTANT:** Pooling maps required in input are computed using __[3D Gray-Code Kernels](https://github.com/Malga-Vision/3DGrayCodeKernels)__ (see paper cited above for more information)\n",
    "\n",
    "For each pair of pooling maps we can identify the following steps:\n",
    "1. **Otsu's adaptive thresholding**: returns a coarse segmentation (GCKsA) based only on max_pooling\n",
    "1. Refinement of GCKsA using **minima and maxima** of the avg_pooling: here we discard connected components of GCKsA smaller than a 5x5 patch and those that do not correspond to areas where there are local extrema\n",
    "1. **Identification of \"present\" and \"past\"** values by using two thresholds (delta_1 and delta_2) over the avg_pooling\n",
    "1. Composition of the **refined segmentation (GCKsR)** subtracting the pixels corresponding to the \"past\" and adding the \"present\" pixels to consolidate the final result.\n",
    "\n",
    "Note that every step contains several morphological operations in order to produce a visually pleasing segmentation with the least number of holes and artifacts.\n",
    "\n",
    "Users can tune variables **delta_1 and delta_2**.\n",
    "\n",
    "We assume that values or the avg_pooling near zero correspond to the past positions and values near 1 correspond to the present. But notice that in some cases it is the opposite so the user needs to invert the name of the variables in first_ref (first refinement that subtracts the \"past\") and second_ref (second refinement that adds the \"present\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to be used on max pooling in order to obtain a first rough segmentation\n",
    "### based on spatio-temporal information\n",
    "\n",
    "def otsuAdaptiveThreshold(pooling_map):\n",
    "    gauss_max = cv2.GaussianBlur(pooling_map,(5,5),0)\n",
    "    \n",
    "    autothr, binary_gauss = cv2.threshold(gauss_max, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    binary_gauss = cv2.dilate(binary_gauss, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)))\n",
    "    binary_gauss = cv2.morphologyEx(binary_gauss, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(4,4)))\n",
    "    binary_gauss = ndimage.binary_fill_holes(binary_gauss)\n",
    "    binary_gauss = binary_gauss*255\n",
    "    binary_gauss = binary_gauss.astype(np.uint8)\n",
    "    \n",
    "    return binary_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to be used on avg pooling\n",
    "def maskPooling(pooling_map, mask):\n",
    "    masked_pooling = np.zeros_like(pooling_map)\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if mask[i,j]==255:\n",
    "                masked_pooling[i,j] = pooling_map[i,j]\n",
    "    \n",
    "    return masked_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to be used on avg_pooling\n",
    "\n",
    "def findPeaks(pooling_map):\n",
    "    if np.max(pooling_map)==1:\n",
    "        pooling_map = pooling_map*255\n",
    "        pooling_map = pooling_map.astype(np.uint8)\n",
    "        \n",
    "    thr_max = np.max(pooling_map)*80/100\n",
    "    \n",
    "    ## finds top 10 local maxima above the background interval\n",
    "    max_peaks = peak_local_max(pooling_map, indices=True,  exclude_border = True, threshold_abs = thr_max, min_distance=5)\n",
    "    if max_peaks.shape[0]>10:\n",
    "            limit = 10\n",
    "    else:\n",
    "        limit = max_peaks.shape[0]\n",
    "    \n",
    "    maxima = np.zeros((limit,3))\n",
    "    if max_peaks.shape[0]>0:\n",
    "        for i in range(limit):\n",
    "            maxima[i,0] = int(max_peaks[i,0])\n",
    "            maxima[i,1] = int(max_peaks[i,1])\n",
    "            maxima[i,2] = pooling_map[int(max_peaks[i,0]), int(max_peaks[i,1])]\n",
    "    \n",
    "    ## finds top 10 local minima below the background interval\n",
    "    thr_min = np.max(cv2.bitwise_not(pooling_map)) * 80 /100\n",
    "    inv = cv2.bitwise_not(pooling_map)\n",
    "    min_peaks = peak_local_max(inv, indices=True, exclude_border = True, threshold_abs = thr_min, min_distance=5)\n",
    "\n",
    "    minima = np.zeros((min_peaks.shape[0],3))\n",
    "    if min_peaks.shape[0]>0:\n",
    "        if min_peaks.shape[0]>10:\n",
    "            limit = 10\n",
    "        else:\n",
    "            limit = min_peaks.shape[0]\n",
    "        for i in range(limit):\n",
    "            minima[i,0] = int(min_peaks[i,0])\n",
    "            minima[i,1] = int(min_peaks[i,1])\n",
    "            minima[i,2] = pooling_map[int(min_peaks[i,0]), int(min_peaks[i,1])]\n",
    "\n",
    "    return minima, maxima\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete connComp of area lower than 25 pixels (approx 5x5 patches)\n",
    "def cleanConnComp(binary_mask):\n",
    "    cc_stats = cv2.connectedComponentsWithStats(binary_mask, 4, cv2.CV_32S)\n",
    "    num_cc = cc_stats[0]\n",
    "    labels = cc_stats[1]\n",
    "    \n",
    "    centroids = cc_stats[3]\n",
    "    connComp = np.copy(binary_mask)\n",
    "    stats = cc_stats[2]\n",
    "    \n",
    "    for i in range(1,stats.shape[0]):\n",
    "        count = 0\n",
    "        if stats[i,4]<=30:     \n",
    "            count=count+1\n",
    "            [x,y] = np.where(labels==i)\n",
    "            connComp[x,y] = 0\n",
    "\n",
    "    return connComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we discard connected components that do not overlap with areas containing local extrema\n",
    "def refineUsingPeaks(pooling_map, minima, maxima):\n",
    "    \n",
    "    cc_stats = cv2.connectedComponentsWithStats(pooling_map, 4, cv2.CV_32S)\n",
    "    num_cc = cc_stats[0]\n",
    "    labels = cc_stats[1]\n",
    "    \n",
    "    centroids = cc_stats[3]\n",
    "    connComp = np.zeros_like(pooling_map)\n",
    "#     print(connComp.shape)\n",
    "    stats = cc_stats[2]\n",
    "    for i in range(1,stats.shape[0]):\n",
    "        points = 0\n",
    "        if stats[i,4]>25:     \n",
    "            for m in range(len(minima)):\n",
    "                x = int(minima[m,0])\n",
    "                y = int(minima[m,1])\n",
    "                if y >= stats[i,0] and y <= (stats[i,0]+ stats[i,2]) and x >= stats[i,1] and x <= (stats[i,1] + stats[i,3]):\n",
    "                    points = points+1\n",
    "            for m in range(len(maxima)):\n",
    "                x = int(maxima[m,0])\n",
    "                y = int(maxima[m,1])\n",
    "                if y >= stats[i,0] and y <= (stats[i,0]+ stats[i,2]) and x >= stats[i,1] and x <= (stats[i,1] + stats[i,3]):\n",
    "                    points = points+1\n",
    "        if points>0:\n",
    "            [x,y] = np.where(labels==i)\n",
    "            connComp[x,y] = 255    \n",
    "    \n",
    "    return connComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.53295969963074\n",
      "0.031430193083080836\n"
     ]
    }
   ],
   "source": [
    "folder = '/home/elenina/Desktop/gck/teatro_della_tosse/video4'\n",
    "# savepath = ###\n",
    "mean_exec = []\n",
    "\n",
    "path_max = sorted(glob.glob(''.join([folder, '/st_max*.npy'])))\n",
    "path_avg = sorted(glob.glob(''.join([folder, '/t_avg*.npy'])))\n",
    "\n",
    "delta_1 = 0.2\n",
    "delta_2 = 0.8\n",
    "\n",
    "start = time.time()\n",
    "for frame in range(len(path_max)):\n",
    "    max_pooling = np.load(path_max[frame])\n",
    "    max_pooling = max_pooling * 255\n",
    "    max_pooling = max_pooling.astype(np.uint8)\n",
    "    avg_pooling = np.load(path_avg[frame])\n",
    "\n",
    "    start_coarse = time.time()\n",
    "    binary_max = otsuAdaptiveThreshold(max_pooling)\n",
    "    binary_max = cleanConnComp(binary_max.astype(np.uint8))\n",
    "#     print('Execution time coarse segmentation: ', time.time() - start_coarse)\n",
    "    start_ref = time.time()\n",
    "    minima, maxima = findPeaks(avg_pooling)\n",
    "    connComp = refineUsingPeaks(binary_max, minima, maxima)\n",
    "    \n",
    "    ### avg_pooling values are included in the range [0,1] with background values around 0.5\n",
    "    \n",
    "    ### we are going to isolate the part of the map near 1 and create a binary mask of it\n",
    "    segm_pos = np.zeros((connComp.shape[0], connComp.shape[1]))\n",
    "    segm_x, segm_y = np.where(avg_pooling>delta_2)\n",
    "    segm_pos[segm_x,segm_y] = 255\n",
    "    cleanedPos = cleanConnComp(segm_pos.astype(np.uint8))\n",
    "    cleanedPos = cv2.dilate(cleanedPos, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))\n",
    "    cleanedPos = cv2.morphologyEx(cleanedPos, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))\n",
    "        \n",
    "    ### in the same way we isolate the values near 0 and create a binary mask of them\n",
    "    segm_neg = np.zeros((connComp.shape[0], connComp.shape[1]))\n",
    "    segm_x, segm_y = np.where(avg_pooling<delta_1)\n",
    "    segm_neg[segm_x,segm_y] = 255\n",
    "    cleanedNeg = cleanConnComp(segm_neg.astype(np.uint8))\n",
    "    cleanedNeg = cv2.dilate(cleanedNeg, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))\n",
    "    cleanedNeg = cv2.morphologyEx(cleanedNeg, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))\n",
    "\n",
    "    ### if we assume that near zero values corresponds to the \"past positions\" of the object\n",
    "    ### then we are going to subtract them to the previously refined mask (connComp)\n",
    "    first_ref = np.copy(connComp)\n",
    "    first_ref[cleanedNeg==255]=0\n",
    "    first_ref = cv2.morphologyEx(first_ref, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(6,6)))\n",
    "    \n",
    "    ### in the same way we consolidate the mask adding the pixels of the \"present\"\n",
    "    second_ref = cv2.bitwise_or(first_ref.astype(np.uint8),cleanedPos.astype(np.uint8))\n",
    "    refined = second_ref\n",
    "    refined = cv2.morphologyEx(refined, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)))\n",
    "    refined = cv2.morphologyEx(refined, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)))\n",
    "\n",
    "    im_out = ndimage.binary_fill_holes(refined)\n",
    "    im_out = im_out*255\n",
    "    im_out = im_out.astype(np.uint8)\n",
    "\n",
    "    cc_stats = cv2.connectedComponentsWithStats(im_out, 4, cv2.CV_32S)\n",
    "    num_cc = cc_stats[0]\n",
    "    labels = cc_stats[1]\n",
    "    centroids = cc_stats[3]\n",
    "    stats = cc_stats[2]\n",
    "    for i in range(1,stats.shape[0]):\n",
    "        points = 0\n",
    "        if stats[i,4]<=30:\n",
    "            [x,y] = np.where(labels==i)\n",
    "            im_out[x,y] = 0\n",
    "    \n",
    "#     plt.imshow(im_out)\n",
    "#     plt.show()\n",
    "\n",
    "    mean_exec.append(time.time()-start_coarse)\n",
    "\n",
    "print(time.time()-start)\n",
    "print(np.mean(mean_exec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
